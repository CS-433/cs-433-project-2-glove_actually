{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99995</td>\n",
       "      <td>can't wait to fake tan tonight ! hate being pale</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99996</td>\n",
       "      <td>&lt;user&gt; darling i lost my internet connection ....</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99997</td>\n",
       "      <td>kanguru defender basic 4 gb usb 2.0 flash driv...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99998</td>\n",
       "      <td>rizan is sad now</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99999</td>\n",
       "      <td>no text back ? yea , he mad</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  label\n",
       "0      <user> i dunno justin read my mention or not ....      1\n",
       "1      because your logic is so dumb , i won't even c...      1\n",
       "2      \" <user> just put casper in a box ! \" looved t...      1\n",
       "3      <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4      visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                  ...    ...\n",
       "99995   can't wait to fake tan tonight ! hate being pale     -1\n",
       "99996  <user> darling i lost my internet connection ....     -1\n",
       "99997  kanguru defender basic 4 gb usb 2.0 flash driv...     -1\n",
       "99998                                   rizan is sad now     -1\n",
       "99999                        no text back ? yea , he mad     -1\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessing as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "def load_data(full = True):\n",
    "    \"\"\"\n",
    "    Loads the Twitter data.\n",
    "    \n",
    "    Args:\n",
    "    full (bool): if False, loads only a part of the data\n",
    "    \n",
    "    Returns:\n",
    "    tweets (pandas dataframe): positive and negative tweets with labels\n",
    "    test_data: unlabelled data for testing\n",
    "    \"\"\"\n",
    "    FULL = ''  \n",
    "    if full:\n",
    "        FULL = '_full'\n",
    "        \n",
    "    POS_TWEETS = 'train_pos.txt'\n",
    "    NEG_TWEETS = 'train_neg.txt'\n",
    "    TEST_DATA = 'test_data.txt'\n",
    "    \n",
    "    with open(POS_TWEETS) as file:\n",
    "        pos_tweets_data = [line.rstrip() for line in file]\n",
    "    pos_tweets = pd.DataFrame(pos_tweets_data, columns=['body'])\n",
    "    pos_tweets['label'] = 1\n",
    "\n",
    "    with open(NEG_TWEETS) as file:\n",
    "        neg_tweets_data = [line.rstrip() for line in file]\n",
    "    neg_tweets = pd.DataFrame(neg_tweets_data, columns=['body'])\n",
    "    neg_tweets['label'] = -1\n",
    "\n",
    "    with open(TEST_DATA) as file:\n",
    "        # removes id at the same time\n",
    "        test_data = [line.rstrip().split(',', 1)[1] for line in file]\n",
    "\n",
    "    test_data = pd.DataFrame(test_data, columns=['body'])\n",
    "\n",
    "    # merge positive and negative datasets\n",
    "    tweets = pd.concat([pos_tweets, neg_tweets], axis = 0)\n",
    "    \n",
    "    return tweets, test_data\n",
    "\n",
    "tweets_raw, test_data_raw = load_data(full = False)\n",
    "\n",
    "tweets_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    body  label\n",
      "0      not know justin read mention not only justin g...      1\n",
      "1                logic dumb not even crop name photo tsk      1\n",
      "2      put casper box ! looved battle ! <hashtag> cra...      1\n",
      "3      thanks sir not trip lil mama .. keep doin ya t...      1\n",
      "4      visit brother tmr bestest birthday gift eveerr...      1\n",
      "...                                                  ...    ...\n",
      "99995           cannot wait fake tan tonight ! hate pale     -1\n",
      "99996  darling lose internet connection .. seem not c...     -1\n",
      "99997  kanguru defender basic <number> gb usb <number...     -1\n",
      "99998                                          rizan sad     -1\n",
      "99999                             no text back ? yea mad     -1\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets_raw.copy()\n",
    "tweets['body'] = pp.preprocess_data(tweets['body'])\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression using tf-idf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer = 'word', ngram_range=(1,1), min_df = 1, max_features = 10000)\n",
    "\n",
    "    train = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    return train, tfidf_vectorizer\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.797, precision = 0.797, recall = 0.797, f1 = 0.797\n"
     ]
    }
   ],
   "source": [
    "list_corpus = tweets[\"body\"].tolist()\n",
    "list_labels = tweets[\"label\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, \n",
    "                                                                                random_state=40)\n",
    "X_train_counts, count_vectorizer = cv(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf, tfidf_vectorizer = tfidf(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "clf_tfidf = LogisticRegression(C=1.0, class_weight='balanced', solver='newton-cg', \n",
    "                         multi_class='multinomial', n_jobs=-1, random_state=40)\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_predicted_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_tfidf, precision_tfidf, recall_tfidf, f1_tfidf = get_metrics(y_test, y_predicted_tfidf)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf, precision_tfidf, \n",
    "                                                                       recall_tfidf, f1_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.802, precision = 0.803, recall = 0.802, f1 = 0.802\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "# accuracy obtained with 10000 features: 0.802\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_tfidf = RandomForestClassifier(criterion='gini', n_estimators=1000,\n",
    "                               random_state=1, n_jobs=-1)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_predicted_rf_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_rf_tfidf, precision_rf_tfidf, recall_rf_tfidf, f1_rf_tfidf = get_metrics(y_test, y_predicted_rf_tfidf)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_rf_tfidf, precision_rf_tfidf, \n",
    "                                                                       recall_rf_tfidf, f1_rf_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy obtained with 10000 features: 0.815\n",
    "# takes some time to count\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_tfidf = SVC(kernel = 'rbf', C = 10.0, random_state=1, gamma=2)\n",
    "\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_predicted_svm_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_svm_tfidf, precision_svm_tfidf, recall_svm_tfidf, f1_svm_tfidf = get_metrics(y_test, y_predicted_svm_tfidf)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_svm_tfidf, precision_svm_tfidf, \n",
    "                                                                       recall_svm_tfidf, f1_svm_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes too much time to count, even with 500 features instead of 10000\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_svc = make_pipeline(StandardScaler(with_mean=False),\n",
    "                        SVC(random_state = 1))\n",
    "param_range = [0.1, 1.0, 10.0, 100.0]\n",
    "param_grid = [{'svc__C': param_range,\n",
    "              'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range,\n",
    "             'svc__gamma': param_range,\n",
    "             'svc__kernel': ['rbf']}]  \n",
    "gs = GridSearchCV(estimator = pipe_svc,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring = 'accuracy',\n",
    "                 cv = 10,\n",
    "                 n_jobs=-1)\n",
    "gs = gs.fit(X_train_tfidf, y_train)\n",
    "print(gs.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
