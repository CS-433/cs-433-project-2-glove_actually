{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP - You need these only the first time you run the code\n",
    "#!git clone https://github.com/facebookresearch/fastText.git\n",
    "#cd fastText\n",
    "#!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module fasttext.FastText in fasttext:\n",
      "\n",
      "NAME\n",
      "    fasttext.FastText\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright (c) 2017-present, Facebook, Inc.\n",
      "    # All rights reserved.\n",
      "    #\n",
      "    # This source code is licensed under the MIT license found in the\n",
      "    # LICENSE file in the root directory of this source tree.\n",
      "\n",
      "FUNCTIONS\n",
      "    cbow(*kargs, **kwargs)\n",
      "    \n",
      "    eprint(*args, **kwargs)\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a model given a filepath and return a model object.\n",
      "    \n",
      "    read_args(arg_list, arg_dict, arg_names, default_values)\n",
      "    \n",
      "    skipgram(*kargs, **kwargs)\n",
      "    \n",
      "    supervised(*kargs, **kwargs)\n",
      "    \n",
      "    tokenize(text)\n",
      "        Given a string of text, tokenize it and return a list of tokens\n",
      "    \n",
      "    train_supervised(*kargs, **kwargs)\n",
      "        Train a supervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input file must must contain at least one label per line. For an\n",
      "        example consult the example datasets which are part of the fastText\n",
      "        repository such as the dataset pulled by classification-example.sh.\n",
      "    \n",
      "    train_unsupervised(*kargs, **kwargs)\n",
      "        Train an unsupervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input field must not contain any labels or use the specified label prefix\n",
      "        unless it is ok for those words to be ignored. For an example consult the\n",
      "        dataset pulled by the example script word-vector-example.sh, which is\n",
      "        part of the fastText repository.\n",
      "\n",
      "DATA\n",
      "    BOW = '<'\n",
      "    EOS = '</s>'\n",
      "    EOW = '>'\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    displayed_errors = {}\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
      "    unsupervised_default = {'autotuneDuration': 300, 'autotuneMetric': 'f1...\n",
      "\n",
      "FILE\n",
      "    /opt/anaconda3/lib/python3.7/site-packages/fasttext/FastText.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "\n",
    "def load_data_fasttext(full = True):\n",
    "    \"\"\"\n",
    "    Loads the Twitter data.\n",
    "    \n",
    "    Args:\n",
    "    full (bool): if False, loads only a part of the data\n",
    "    \n",
    "    Returns:\n",
    "    tweets (pandas dataframe): positive and negative tweets with labels\n",
    "    test_data: unlabelled data for testing\n",
    "    \"\"\"\n",
    "    \n",
    "    FULL = ''  \n",
    "    if full:\n",
    "        FULL = '_full'\n",
    "        \n",
    "    POS_TWEETS = DATA_PATH + 'train_pos' + FULL + '.txt'\n",
    "    NEG_TWEETS = DATA_PATH + 'train_neg' + FULL + '.txt'\n",
    "    TEST_DATA = DATA_PATH + 'test_data.txt'\n",
    "    \n",
    "    with open(POS_TWEETS) as file:\n",
    "        pos_tweets_data = [line.rstrip() for line in file]\n",
    "    pos_tweets = pd.DataFrame(pos_tweets_data, columns=['body'])\n",
    "    pos_tweets['label'] = \"__label__happyface\"\n",
    "    pos_tweets = reindex_df(pos_tweets)\n",
    "    \n",
    "    with open(NEG_TWEETS) as file:\n",
    "        neg_tweets_data = [line.rstrip() for line in file]\n",
    "    neg_tweets = pd.DataFrame(neg_tweets_data, columns=['body'])\n",
    "    neg_tweets['label'] = \"__label__sadface\"\n",
    "    neg_tweets = reindex_df(neg_tweets)\n",
    "\n",
    "    with open(TEST_DATA) as file:\n",
    "        # removes id at the same time\n",
    "        test_data = [line.rstrip().split(',', 1)[1] for line in file]\n",
    "\n",
    "    test = pd.DataFrame(test_data, columns=['body'])\n",
    "\n",
    "    # take 70% as train data, 30% as validation data (equal pos and neg)\n",
    "    #pos_X_train, pos_X_test, pos_y_train, pos_y_test = train_test_split(pos_tweets['body'], pos_tweets['label'], test_size=0.3, random_state=42)\n",
    "    #neg_X_train, neg_X_test, neg_y_train, neg_y_test = train_test_split(neg_tweets['body'], neg_tweets['label'], test_size=0.3, random_state=42)\n",
    "    \n",
    "    # merge positive and negative datasets\n",
    "    tweets = pd.concat([pos_tweets, neg_tweets], axis = 0)\n",
    "    \n",
    "    # split into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(tweets['body'], tweets['label'], test_size=0.3, random_state=42)\n",
    "    \n",
    "    train = pd.concat([X_train, y_train], axis = 1)\n",
    "    val = pd.concat([X_val, y_val], axis = 1)\n",
    "    \n",
    "    train = reindex_df(train)\n",
    "    val = reindex_df(val)\n",
    "    \n",
    "    return tweets, train, val, X_train, X_val, y_train, y_val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_df(df):\n",
    "    \"\"\"\n",
    "    Reindexes a given dataframe for the FastText format (i.e. label first, body second)\n",
    "    \n",
    "    Args:\n",
    "    df (pandas dataframe): tweets with columns indexed as ['body', 'label']\n",
    "    \n",
    "    Returns:\n",
    "    df_reindexed (pandas dataframe): tweets with columns indexed as ['body', 'label']\n",
    "    \"\"\"\n",
    "    \n",
    "    columnsTitles = ['label', 'body'] \n",
    "    df_reindexed = df.reindex(columns=columnsTitles)\n",
    "    \n",
    "    return df_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, train, val, X_train, X_val, y_train, y_val, test = load_data_fasttext(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'train_full.txt', train.values, fmt='%s')\n",
    "np.savetxt(r'val_full.txt', val.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"train_full.txt\", lr=1.0, epoch=1, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 0.8639346666666666, 0.8639346666666666)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"val_full.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/o hyperparameter tuning:\n",
    "\n",
    "dataset=small: (60000, 0.82505, 0.82505)\n",
    "dataset=full: (750000, 0.8355986666666667, 0.8355986666666667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/ some hyperparameter tuning:\n",
    "\n",
    "dataset=small, lr=1.0, epoch=1, wordNgrams=3: (60000, 0.8371166666666666, 0.8371166666666666)\n",
    "\n",
    "dataset=full, lr=1.0, epoch=1, wordNgrams=3: (750000, 0.8639346666666666, 0.8639346666666666)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
