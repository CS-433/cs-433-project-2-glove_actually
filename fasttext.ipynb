{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analysis using fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP - You need these only the first time you run the code\n",
    "#!git clone https://github.com/facebookresearch/fastText.git\n",
    "#cd fastText\n",
    "#!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ft_helpers as fth\n",
    "import preprocessing as pp\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your (hyper)parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If selected false, only tests on validation data, otherwise creates submission .csv\n",
    "CREATE_SUBMISSION = True \n",
    "\n",
    "# If selected true, creates a .csv file with the prediction probability for each tweet\n",
    "GET_PROBABILITIES = True\n",
    "\n",
    "# Select if you want to use preprocessed data or not\n",
    "PREPROCESS = False\n",
    "\n",
    "# Select the number of ngrams you want to use\n",
    "NGRAMS = 3 \n",
    "\n",
    "# Choose a submission file postfix (so that you don't overwrite your results)\n",
    "SUBMISSION_POSTFIX = '_' + str(NGRAMS) + 'grams_50epochs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, test = fth.load_data(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    tweets['body'] = pp.preprocess_data(tweets['body'])\n",
    "    test['body'] = pp.preprocess_data(test['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = fth.train_val_split(tweets['body'], tweets['label'], 0.2, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the dataframes according to fasttext's format\n",
    "train, val, test = fth.reindex_dfs(CREATE_SUBMISSION, train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data .txt files to be used in fasttext model\n",
    "train_txt, val_txt, test_txt = fth.save_txt(train, val, test, SUBMISSION_POSTFIX, CREATE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=train_txt, lr=0.15, epoch=2, wordNgrams=NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(val_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_SUBMISSION == True:\n",
    "    filename = 'output' + SUBMISSION_POSTFIX + '.csv'\n",
    "    fth.create_csv_submission(model, test, filename)\n",
    "    \n",
    "if GET_PROBABILITIES == True:\n",
    "    filename = 'prob' + SUBMISSION_POSTFIX + '.csv'\n",
    "    fth.create_probabilities_csv(model, test, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=1.0, epoch=i, wordNgrams=NGRAMS)\n",
    "    print(i, model.test(val_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**number of epochs, F1-score**\n",
    "- 1, 0.864954\n",
    "- **2, 0.86699**\n",
    "- 3, 0.860868\n",
    "- 4, 0.85543\n",
    "- 5, 0.85203\n",
    "- 6, 0.850778\n",
    "- 7, 0.850452\n",
    "- 8, 0.84953\n",
    "- 9, 0.849226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0.05\n",
    "while i <= 1.0:\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=i, epoch=2, wordNgrams=NGRAMS)\n",
    "    print(i, model.test(val_txt))\n",
    "    i += 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**learning rate, F1-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **0.1, 0.868022**\n",
    "- 0.2, 0.867472\n",
    "- 0.3, 0.867402\n",
    "- 0.4, 0.867426\n",
    "- 0.5, 0.867228\n",
    "- 0.6, 0.86709\n",
    "- 0.7, 0.867224\n",
    "- 0.8, 0.867068\n",
    "- 0.9, 0.86718\n",
    "- 1.0, 0.867068"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'n'-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=0.1, epoch=2, wordNgrams=i)\n",
    "    print(i, model.test(val_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n, F1-score**\n",
    "- 1, 0.833644\n",
    "- 2, 0.865526\n",
    "- **3, 0.86983**\n",
    "- 4, 0.867922\n",
    "- 5, 0.865792\n",
    "- 6, 0.863836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastText's automatic hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auto = fasttext.train_supervised(input=train_txt, lr=0.1, epoch=2, wordNgrams=NGRAMS, autotuneValidationFile=val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_auto.test(val_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model created using fastText's automatic hyperparameter optimization gives accuracy 86.4% and F1-score 86.6 on AICrowd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth.create_csv_submission(model_auto, test, 'ft_completely_auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fth.create_probabilities_csv(model_auto, test, 'ft_completely_auto_prob.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only  n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ngram model outputs\n",
    "df_2grams = pd.read_csv(\"output_2grams.csv\") \n",
    "df_3grams = pd.read_csv(\"output_3grams.csv\") \n",
    "df_4grams = pd.read_csv(\"output_4grams.csv\") \n",
    "df_5grams = pd.read_csv(\"output_5grams.csv\") \n",
    "df_6grams = pd.read_csv(\"output_6grams.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ensemble model using majority voting\n",
    "df_ensemble = df_2grams.copy()\n",
    "df_ensemble['Id'] = df_2grams.index + 1\n",
    "df_ensemble['Prediction'] = (df_2grams['Prediction'] + df_3grams['Prediction'] + df_4grams['Prediction'] + df_5grams['Prediction'] + df_6grams['Prediction']).apply(lambda x: fth.sign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe into csv    \n",
    "df_ensemble.to_csv('ensemble_ngrams.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of 2,3,4,5,6-grams gives accuracy 86.5% and F1-score 86.7 on AICrowd. This is 0.3% better accuracy than using the best single classifier, i.e. 3-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using n-grams + automatic hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read automatically optimized model output\n",
    "df_auto = pd.read_csv(\"ft_auto.csv\") \n",
    "\n",
    "#Create an ensemble model using majority voting\n",
    "df_ensemble['Prediction'] = (df_2grams['Prediction'] + 2*df_3grams['Prediction'] + df_4grams['Prediction'] + df_5grams['Prediction'] + df_6grams['Prediction'] + df_auto['Prediction']).apply(lambda x: sign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe into csv    \n",
    "df_ensemble.to_csv('ensemble_with_auto_3gramsemphasis.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of 2,3,4,5,6-grams and automatic hyperparameter optimized model, with an emphasis on the automatic model gives accuracy 86.5% and F1-score 86.7 on AICrowd. No improvement from the ensemble without the automatic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of 2,3,4,5,6-grams and automatic hyperparameter optimized model, with an emphasis on the 3-grams model gives accuracy 86.5% and F1-score 86.8 on AICrowd. Emphasizing the best single model slightly improves the F1-score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
