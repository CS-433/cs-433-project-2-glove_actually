{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analysis using fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP - You need these only the first time you run the code\n",
    "#!git clone https://github.com/facebookresearch/fastText.git\n",
    "#cd fastText\n",
    "#!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ft_helpers as fth\n",
    "import preprocessing as pp\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your (hyper)parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If selected false, only tests on validation data, otherwise creates submission .csv\n",
    "CREATE_SUBMISSION = True \n",
    "\n",
    "# Select if you want to use preprocessed data or not\n",
    "PREPROCESS = False\n",
    "\n",
    "# Select the number of ngrams you want to use\n",
    "NGRAMS = 3 \n",
    "\n",
    "# Choose a submission file postfix (so that you don't overwrite your results)\n",
    "SUBMISSION_POSTFIX = '_3grams' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, test = fth.load_data(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    tweets['body'] = pp.preprocess_data(tweets['body'])\n",
    "    test['body'] = pp.preprocess_data(test['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = fth.train_val_split(tweets['body'], tweets['label'], 0.2, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = fth.reindex_dfs(CREATE_SUBMISSION, train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt, val_txt, test_txt = fth.save_txt(train, val, test, SUBMISSION_POSTFIX, CREATE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=train_txt, lr=0.1, epoch=2, wordNgrams=NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 0.869858, 0.869858)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(val_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99518883228302,\n",
       " 0.5997893810272217,\n",
       " 0.5740494132041931,\n",
       " 0.9601660966873169,\n",
       " 0.9867045879364014]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can be used for ensemble classifiers\n",
    "predictions, probabilities = fth.get_prediction_probabilities(model, test)\n",
    "probabilities[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_SUBMISSION == True:\n",
    "    filename = 'output' + SUBMISSION_POSTFIX + '.csv'\n",
    "    fth.create_csv_submission(model, test, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (500000, 0.864954, 0.864954)\n",
      "2 (500000, 0.86699, 0.86699)\n",
      "3 (500000, 0.860868, 0.860868)\n",
      "4 (500000, 0.85543, 0.85543)\n",
      "5 (500000, 0.85203, 0.85203)\n",
      "6 (500000, 0.850778, 0.850778)\n",
      "7 (500000, 0.850452, 0.850452)\n",
      "8 (500000, 0.84953, 0.84953)\n",
      "9 (500000, 0.849226, 0.849226)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=1.0, epoch=i, wordNgrams=NGRAMS)\n",
    "    print(i, model.test(val_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 (500000, 0.868022, 0.868022)\n",
      "0.2 (500000, 0.867472, 0.867472)\n",
      "0.30000000000000004 (500000, 0.867402, 0.867402)\n",
      "0.4 (500000, 0.867426, 0.867426)\n",
      "0.5 (500000, 0.867228, 0.867228)\n",
      "0.6 (500000, 0.86709, 0.86709)\n",
      "0.7 (500000, 0.867224, 0.867224)\n",
      "0.7999999999999999 (500000, 0.867068, 0.867068)\n",
      "0.8999999999999999 (500000, 0.86718, 0.86718)\n",
      "0.9999999999999999 (500000, 0.867096, 0.867096)\n"
     ]
    }
   ],
   "source": [
    "i = 0.1\n",
    "while i <= 1.0:\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=i, epoch=2, wordNgrams=NGRAMS)\n",
    "    print(i, model.test(val_txt))\n",
    "    i += 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'n'-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (500000, 0.833644, 0.833644)\n",
      "2 (500000, 0.865526, 0.865526)\n",
      "3 (500000, 0.86983, 0.86983)\n",
      "4 (500000, 0.867922, 0.867922)\n",
      "5 (500000, 0.865792, 0.865792)\n",
      "6 (500000, 0.863836, 0.863836)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,7):\n",
    "    model = fasttext.train_supervised(input=train_txt, lr=0.1, epoch=2, wordNgrams=i)\n",
    "    print(i, model.test(val_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Trying different number of epochs:\n",
    "- 1 (500000, 0.864954, 0.864954)\n",
    "- 2 (500000, 0.86699, 0.86699)\n",
    "- 3 (500000, 0.860868, 0.860868)\n",
    "- 4 (500000, 0.85543, 0.85543)\n",
    "- 5 (500000, 0.85203, 0.85203)\n",
    "- 6 (500000, 0.850778, 0.850778)\n",
    "- 7 (500000, 0.850452, 0.850452)\n",
    "- 8 (500000, 0.84953, 0.84953)\n",
    "- 9 (500000, 0.849226, 0.849226)\n",
    "\n",
    "### Trying different learning rates:\n",
    "- 0.1 (500000, 0.868022, 0.868022)\n",
    "- 0.2 (500000, 0.867472, 0.867472)\n",
    "- 0.30000000000000004 (500000, 0.867402, 0.867402)\n",
    "- 0.4 (500000, 0.867426, 0.867426)\n",
    "- 0.5 (500000, 0.867228, 0.867228)\n",
    "- 0.6 (500000, 0.86709, 0.86709)\n",
    "- 0.7 (500000, 0.867224, 0.867224)\n",
    "- 0.7999999999999999 (500000, 0.867068, 0.867068)\n",
    "- 0.8999999999999999 (500000, 0.86718, 0.86718)\n",
    "- 0.9999999999999999 (500000, 0.867096, 0.867096)\n",
    "\n",
    "### Trying different number of ngrams:\n",
    "- 1 (500000, 0.833644, 0.833644)\n",
    "- 2 (500000, 0.865526, 0.865526)\n",
    "- 3 (500000, 0.86983, 0.86983)\n",
    "- 4 (500000, 0.867922, 0.867922)\n",
    "- 5 (500000, 0.865792, 0.865792)\n",
    "- 6 (500000, 0.863836, 0.863836)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue, apply the methods suggested in this tutorial: https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "More FastText documentation here: https://fasttext.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
